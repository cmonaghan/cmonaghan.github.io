---
layout: post
title:  "100 Days of Gen AI: Day 45"
---

I've been trying out Cursor this week at Benchling and wanted to share some of my experiences. I've found it to be far superior to Github Copilot, which I've used for several months. In particular it seems able to find and incorporate relevant context from across our moderately sized infra codebase. I've even had good luck refactoring complex Terraform.

##### Here's one experience worth highlighting in more detail

My goal was to take a resource that had been previously created in the AWS UI, and to import this into Terraform so it could be managed using Infrastructure-as-Code moving forward. This was a resource type not previously in our codebase, and a resource I've never used before. This type of infra work can be tedious.

To import existing resources into Terraform, the general development flow is:
1. create a placeholder empty terraform resource (e.g. `resource "aws_ce_cost_category" "cost_type" {}`)
2. read the Terraform provider docs and determine how to import the particular resource
3. run the proper `terraform import` command
4. run `terraform plan` to determine resource drift, which reveals the ways in which our Terraform configuration is different from what is actually running in AWS
5. modify the resource from step 1 to match the config revealed in step 4
6. cross-reference the AWS UI to try to guess what values need to be set when it's not clear from documentation or the diff in step 4
7. read the Terraform provider docs
8. run `terraform plan`, it errors, you realize that some fields cannot be set because they are computed fields, or for some other obscure reason
9. repeat steps 4-8 for several cycles until you finally get to a `terraform plan` that results in `"No changes"`

Cursor made this development loop quite painless, generating the probable resource configurations and the commands to test them. It took about 7 or 8 iterations to get to a near-complete solution. It did get stuck on one part, but I also got stuck when I took over because the actual setting in AWS was at odds with what is in the documentation and what is allowed in the terraform provider, so it was actually not possible to get to a perfectly matching configuration. I also never had to communicate the specifics of the above Terraform development loop -- it already knew the drill. It was also able to find relevant files throughout the codebase without prompting, process terminal output, process images, and read relevant documentation on the internet.

I also found it wasn't able to follow really chatty terminal output, or have the patience for long-running terminal commands to complete. In these situations it would give up on those after several seconds (10s?). I found it was more effective to just run these types of commands myself and manually paste the relevant terminal output back into the AI chat once complete.

Overall a great experience!
